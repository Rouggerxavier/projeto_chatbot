import os

import streamlit as st
from dotenv import load_dotenv

from langchain_groq import ChatGroq
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage

# ---------------------------------------------------
# ConfiguraÃ§Ã£o inicial
# ---------------------------------------------------
st.set_page_config(
    page_title="Chatbot Constrular",
    page_icon="ğŸ—ï¸",
    layout="centered",
)

load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY:
    st.error("GROQ_API_KEY nÃ£o encontrada. Verifique seu arquivo .env")
    st.stop()

# Opcional, mas ajuda algumas libs a encontrarem:
os.environ["GROQ_API_KEY"] = GROQ_API_KEY

# ---------------------------------------------------
# Modelo Groq
# ---------------------------------------------------
chat_model = ChatGroq(
    model="llama-3.1-8b-instant",  # pode trocar se quiser
    temperature=0.3,
)

SYSTEM_PROMPT = """
VocÃª Ã© um atendente virtual de uma loja de material de construÃ§Ã£o chamada *Constrular*.

InformaÃ§Ãµes da loja:
- HorÃ¡rio de funcionamento: segunda a sexta, das 7h Ã s 18h, e sÃ¡bado das 7h as 12h.
- Fazemos entrega para os bairros: ManaÃ­ra, Intermares, Aeroclube, TambÃ¡u, e todo o Bessa.
- Prazo mÃ©dio de entrega: no mesmo dia para pedidos atÃ© 15h, ou no dia seguinte.
- Formas de pagamento: dinheiro, cartÃ£o de crÃ©dito/dÃ©bito, PIX.

CatÃ¡logo bÃ¡sico (exemplos, use para sugerir produtos):
- Cimento CP II 50kg: uso geral em obras, bom para reboco e assentamento.
- Cimento CP III 50kg: indicado para fundaÃ§Ãµes, lajes e estruturas mais pesadas.
- Areia mÃ©dia: usada para reboco e assentamento de tijolos.
- Tijolo 8 furos: indicado para paredes internas.
- Tinta acrÃ­lica fosca para interior: boa para paredes internas.
- Tinta acrÃ­lica semibrilho para exterior: indicada para Ã¡reas externas.

Regras:
- Sempre pergunte o que a pessoa estÃ¡ construindo/reformando antes de indicar produtos.
- Nunca invente preÃ§o. Se perguntarem valores, pergunte primeiro se ele quer mais algo para deixar todo o pedido completo e pergunte em seguida se ele jÃ¡ quer ir pro pagamento e assim teria que contatar um atendente.
- Caso o cliente fale que nÃ£o precisa de mais nada, ou que sÃ³ precisa de tal material que foi pedido, nÃ£o ofereÃ§a mais nada para nÃ£o incomodar, mas apenas em casos como esse.
- Fale sempre em portuguÃªs do Brasil, em tom educado, simples e direto.
"""


# ---------------------------------------------------
# HeurÃ­stica: precisa de atendente humano?
# ---------------------------------------------------
def detect_needs_human(user_message: str) -> bool:
    text = user_message.lower()

    palavras_atendente = [
        "atendente",
        "vendedor",
        "vendedora",
        "humano",
        "pessoa",
        "falar com alguÃ©m",
        "falar com uma pessoa",
        "me liga",
        "pode me ligar",
        "quero falar com",
        "transferir para",
        "me passa para",
    ]

    palavras_sensiveis = [
        "desconto",
        "condiÃ§Ã£o de pagamento",
        "condiÃ§Ãµes de pagamento",
        "parcelamento",
        "preÃ§o exato",
        "valor exato",
        "orÃ§amento detalhado",
        "negociar preÃ§o",
        "negociar valor",
        "prazo de pagamento",
        "orÃ§amento",
    ]

    if any(p in text for p in palavras_atendente):
        return True

    if any(p in text for p in palavras_sensiveis):
        return True

    return False


# ---------------------------------------------------
# Estado da sessÃ£o
# ---------------------------------------------------
if "messages" not in st.session_state:
    st.session_state["messages"]: list[dict] = []  # {role: "user"/"assistant", "content": str, "needs_human": bool}


def build_langchain_history() -> list[BaseMessage]:
    """Converte o histÃ³rico do Streamlit em mensagens do LangChain."""
    history: list[BaseMessage] = []
    for msg in st.session_state["messages"]:
        if msg["role"] == "user":
            history.append(HumanMessage(content=msg["content"]))
        else:
            history.append(AIMessage(content=msg["content"]))
    return history


def generate_reply(message: str) -> tuple[str, bool]:
    """Gera resposta usando Groq + lÃ³gica de encaminhar para humano."""
    needs_human = detect_needs_human(message)
    history = build_langchain_history()

    # Se for caso de humano, nÃ£o chama o modelo
    if needs_human:
        answer = (
            "Entendi, vocÃª quer falar com um atendente humano. "
            "Vou encaminhar seu atendimento para uma pessoa da equipe."
        )
        return answer, True

    # Caso normal: chama modelo
    messages: list[BaseMessage] = [
        SystemMessage(content=SYSTEM_PROMPT),
        *history,
        HumanMessage(content=message),
    ]

    response = chat_model.invoke(messages)
    return response.content, False


# ---------------------------------------------------
# UI â€“ Sidebar
# ---------------------------------------------------
with st.sidebar:
    st.markdown("## ğŸ—ï¸ Constrular Chatbot")
    st.markdown(
        """
Bem-vindo ao assistente virtual da **Constrular**!

Aqui vocÃª pode:
- Tirar dÃºvidas sobre materiais de construÃ§Ã£o  
- Pedir sugestÃµes para reforma/obra  
- Entender melhor que produto usar em cada situaÃ§Ã£o  

âš ï¸ **PreÃ§os reais** nÃ£o sÃ£o informados aqui.  
Para valores exatos e formas de pagamento detalhadas,
um atendente humano serÃ¡ acionado.
        """
    )
    if st.button("ğŸ” Limpar conversa"):
        st.session_state["messages"] = []
        st.experimental_rerun()

# ---------------------------------------------------
# UI â€“ CabeÃ§alho
# ---------------------------------------------------
st.title("ğŸ—ï¸ Assistente Virtual Constrular")
st.caption("Tire suas dÃºvidas sobre materiais de construÃ§Ã£o de forma rÃ¡pida e simples.")

# ---------------------------------------------------
# Mostrar histÃ³rico de mensagens
# ---------------------------------------------------
for msg in st.session_state["messages"]:
    if msg["role"] == "user":
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(msg["content"])
    else:
        with st.chat_message("assistant", avatar="ğŸ—ï¸"):
            st.markdown(msg["content"])
            if msg.get("needs_human"):
                st.write("ğŸ§‘â€ğŸ’¼ *Esse atendimento serÃ¡ encaminhado para um atendente humano.*")

# ---------------------------------------------------
# Entrada de mensagem do usuÃ¡rio
# ---------------------------------------------------
user_input = st.chat_input("Digite sua dÃºvida sobre materiais de construÃ§Ã£o...")

if user_input:
    # adiciona mensagem do usuÃ¡rio
    st.session_state["messages"].append(
        {"role": "user", "content": user_input, "needs_human": False}
    )
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(user_input)

    # gera resposta
    with st.chat_message("assistant", avatar="ğŸ—ï¸"):
        with st.spinner("Pensando..."):
            reply, needs_human = generate_reply(user_input)
        st.markdown(reply)
        if needs_human:
            st.write("ğŸ§‘â€ğŸ’¼ *Esse atendimento serÃ¡ encaminhado para um atendente humano.*")

    # salva mensagem do bot no histÃ³rico
    st.session_state["messages"].append(
        {"role": "assistant", "content": reply, "needs_human": needs_human}
    )
